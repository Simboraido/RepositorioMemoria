#!/usr/bin/env python3
"""
ğŸ§¬ IMPLEMENTACIÃ“N EVOLVEGCN-H - EVOLVING GRAPH CONVOLUTIONAL NETWORKS
=====================================================================

ImplementaciÃ³n completa de EvolveGCN-H para predicciÃ³n de enlaces en redes 
semÃ¡nticas temporales usando los datos de metadatos acadÃ©micos.

CaracterÃ­sticas:
- EvolveGCN-H (Historical) con GRU para evoluciÃ³n temporal
- EvoluciÃ³n de parÃ¡metros de GCN a travÃ©s del tiempo
- Optimizado para secuencias temporales largas (25 aÃ±os)
- ComparaciÃ³n directa vs baseline y TDGNN

Basado en:
"EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs"
Pareja et al., AAAI 2020

Autor: Sistema de ImplementaciÃ³n EvolveGCN
Fecha: Julio 2025
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'External_repos', 'EvolveGCN'))

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import pandas as pd
import networkx as nx
from sklearn.metrics import roc_auc_score, average_precision_score, f1_score
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json
import pickle
from typing import Dict, List, Tuple, Optional
from collections import defaultdict
import time
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Importar mÃ³dulos de EvolveGCN
try:
    from egcn_h import EGCN_H
    from utils import build_random_hyper_params
except ImportError:
    print("âš ï¸ No se pudo importar EvolveGCN. Usando implementaciÃ³n propia.")


class EvolveGCNH(nn.Module):
    """
    ğŸ§¬ EvolveGCN-H - Historical Evolution
    ====================================
    
    VersiÃ³n simplificada de EvolveGCN-H que evoluciona los parÃ¡metros de GCN
    usando GRU basado en la historia temporal.
    """
    
    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int, 
                 num_layers: int = 2, dropout: float = 0.1):
        super(EvolveGCNH, self).__init__()
        
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        self.num_layers = num_layers
        self.dropout = dropout
        
        # GRU para evoluciÃ³n temporal de parÃ¡metros
        self.weight_evolve_gru = nn.GRU(
            input_size=hidden_dim * hidden_dim,  # TamaÃ±o de matriz de pesos GCN
            hidden_size=hidden_dim * hidden_dim,
            num_layers=1,
            batch_first=True
        )
        
        # ParÃ¡metros iniciales de GCN
        self.initial_weights = nn.Parameter(
            torch.randn(hidden_dim, hidden_dim) * 0.1
        )
        
        # Capas fijas
        self.input_projection = nn.Linear(input_dim, hidden_dim)
        self.output_projection = nn.Linear(hidden_dim, output_dim)
        
        # Link predictor
        self.link_predictor = nn.Sequential(
            nn.Linear(output_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim // 2, 1)
        )
        
        # Estado oculto del GRU
        self.gru_hidden = None
        
    def reset_parameters(self):
        """Reinicia parÃ¡metros del modelo"""
        if self.gru_hidden is not None:
            self.gru_hidden = self.gru_hidden.detach()
            self.gru_hidden.zero_()
        
    def evolve_weights(self, time_step: int) -> torch.Tensor:
        """
        Evoluciona los pesos de GCN usando GRU
        
        Args:
            time_step: Paso temporal actual
        
        Returns:
            Nuevos pesos de GCN evolucionados
        """
        batch_size = 1
        device = self.initial_weights.device
        
        # Preparar input para GRU (pesos actuales aplanados)
        current_weights = self.initial_weights.view(1, 1, -1).detach()
        
        # Inicializar estado oculto si es necesario
        if self.gru_hidden is None:
            self.gru_hidden = torch.zeros(
                1, batch_size, self.hidden_dim * self.hidden_dim,
                device=device, requires_grad=False
            )
        else:
            # Detach para evitar problemas de gradiente
            self.gru_hidden = self.gru_hidden.detach()
        
        # Evolucionar pesos con GRU
        output, self.gru_hidden = self.weight_evolve_gru(
            current_weights, self.gru_hidden
        )
        
        # Reshape a matriz de pesos
        evolved_weights = output.view(self.hidden_dim, self.hidden_dim)
        
        return evolved_weights
        
    def gcn_layer(self, x: torch.Tensor, edge_index: torch.Tensor, 
                  weights: torch.Tensor) -> torch.Tensor:
        """
        Capa GCN con pesos evolucionados
        
        Args:
            x: Features de nodos [num_nodes, hidden_dim]
            edge_index: Ãndices de aristas [2, num_edges]
            weights: Pesos GCN evolucionados [hidden_dim, hidden_dim]
        
        Returns:
            Features actualizadas [num_nodes, hidden_dim]
        """
        num_nodes = x.size(0)
        
        # Crear matriz de adyacencia
        adj = torch.zeros(num_nodes, num_nodes, device=x.device)
        if edge_index.size(1) > 0:
            adj[edge_index[0], edge_index[1]] = 1.0
            
        # NormalizaciÃ³n simÃ©trica
        degree = adj.sum(dim=1)
        degree[degree == 0] = 1  # Evitar divisiÃ³n por cero
        d_inv_sqrt = torch.diag(degree.pow(-0.5))
        adj_norm = d_inv_sqrt @ adj @ d_inv_sqrt
        
        # Aplicar convoluciÃ³n con pesos evolucionados
        x_transformed = x @ weights
        output = adj_norm @ x_transformed
        
        return output
    
    def forward(self, temporal_graphs: List[Dict], target_pairs: torch.Tensor,
                time_step: int = 0) -> torch.Tensor:
        """
        Forward pass de EvolveGCN-H
        
        Args:
            temporal_graphs: Lista de grafos temporales
            target_pairs: Pares de nodos a predecir [batch_size, 2]
            time_step: Paso temporal actual
        
        Returns:
            Probabilidades de enlaces [batch_size, 1]
        """
        if not temporal_graphs:
            # Crear output dummy si no hay grafos
            batch_size = target_pairs.size(0)
            return torch.zeros(batch_size, 1, device=target_pairs.device)
        
        # Usar el primer grafo temporal (simplificado)
        graph_data = temporal_graphs[0]
        edge_index = graph_data['edge_index']
        node_features = graph_data.get('node_features')
        
        if node_features is None:
            # Crear features dummy
            num_nodes = max(edge_index.max().item() + 1, target_pairs.max().item() + 1)
            node_features = torch.randn(num_nodes, self.input_dim, device=edge_index.device)
        
        # ProyecciÃ³n inicial
        x = self.input_projection(node_features)
        
        # Evolucionar pesos GCN
        evolved_weights = self.evolve_weights(time_step)
        
        # Aplicar capas GCN evolucionadas
        for layer in range(self.num_layers):
            x = self.gcn_layer(x, edge_index, evolved_weights)
            x = F.relu(x)
            x = F.dropout(x, self.dropout, training=self.training)
        
        # ProyecciÃ³n final
        node_embeddings = self.output_projection(x)
        
        # PredicciÃ³n de enlaces
        source_embeddings = node_embeddings[target_pairs[:, 0]]
        target_embeddings = node_embeddings[target_pairs[:, 1]]
        
        # Combinar embeddings
        pair_embeddings = torch.cat([source_embeddings, target_embeddings], dim=1)
        
        # Predecir probabilidad de enlace
        link_scores = self.link_predictor(pair_embeddings)
        link_probs = torch.sigmoid(link_scores)
        
        return link_probs


class TemporalGraphProcessor:
    """
    ğŸ“Š Procesador de Grafos Temporales para EvolveGCN
    ================================================
    
    Convierte datos de NetworkX a formato compatible con EvolveGCN
    """
    
    def __init__(self, temporal_networks_path: str = "../temporal_networks/networks"):
        self.temporal_networks_path = Path(temporal_networks_path)
        self.node_to_id = {}
        self.id_to_node = {}
        self.temporal_graphs = []
        
    def load_and_process(self) -> Dict:
        """Carga y procesa todas las redes temporales"""
        print("ğŸ“‚ Cargando redes temporales para EvolveGCN...")
        
        network_files = list(self.temporal_networks_path.glob("semantic_network_*.graphml"))
        network_files.sort()
        
        print(f"Encontrados {len(network_files)} archivos de red")
        
        all_nodes = set()
        temporal_data = []
        
        # Cargar todos los grafos
        for i, file_path in enumerate(network_files):
            period = file_path.stem.replace('semantic_network_', '')
            print(f"  ğŸ“ˆ Cargando {period}...")
            
            try:
                G = nx.read_graphml(file_path)
                temporal_data.append({
                    'period': period,
                    'graph': G,
                    'timestamp': self._period_to_timestamp(period)
                })
                all_nodes.update(G.nodes())
                
            except Exception as e:
                print(f"  âŒ Error cargando {file_path}: {e}")
                continue
        
        # Crear mapeo de nodos
        self.node_to_id = {node: i for i, node in enumerate(sorted(all_nodes))}
        self.id_to_node = {i: node for node, i in self.node_to_id.items()}
        
        print(f"ğŸ“Š Total de nodos Ãºnicos: {len(all_nodes)}")
        
        # Convertir a formato tensor
        for data in temporal_data:
            graph_tensor = self._convert_to_tensor(data['graph'], data['timestamp'])
            self.temporal_graphs.append(graph_tensor)
        
        return {
            'num_nodes': len(all_nodes),
            'num_periods': len(temporal_data),
            'node_mapping': {'node_to_id': self.node_to_id, 'id_to_node': self.id_to_node},
            'temporal_graphs': self.temporal_graphs
        }
    
    def _period_to_timestamp(self, period: str) -> float:
        """Convierte perÃ­odo a timestamp"""
        try:
            year_part = period.split('-')[0]
            start_year = int(year_part)
            return float(start_year - 2000)
        except:
            return 0.0
    
    def _convert_to_tensor(self, G: nx.Graph, timestamp: float) -> Dict:
        """Convierte grafo NetworkX a tensores PyTorch"""
        
        # Convertir aristas
        edges = []
        edge_weights = []
        
        for u, v, data in G.edges(data=True):
            if u in self.node_to_id and v in self.node_to_id:
                u_id = self.node_to_id[u]
                v_id = self.node_to_id[v]
                
                edges.append([u_id, v_id])
                edges.append([v_id, u_id])  # Grafo no dirigido
                
                weight = data.get('weight', 1.0)
                edge_weights.extend([weight, weight])
        
        # Crear features de nodos bÃ¡sicas
        num_nodes = len(self.node_to_id)
        node_features = self._create_node_features(G, num_nodes)
        
        graph_data = {
            'timestamp': timestamp,
            'edge_index': torch.tensor(edges).t().contiguous() if edges else torch.empty((2, 0), dtype=torch.long),
            'edge_weights': torch.tensor(edge_weights, dtype=torch.float) if edge_weights else torch.empty(0),
            'node_features': node_features,
            'num_nodes': num_nodes,
            'num_edges': len(edges)
        }
        
        return graph_data
    
    def _create_node_features(self, G: nx.Graph, num_nodes: int) -> torch.Tensor:
        """Crea features bÃ¡sicas para los nodos"""
        feature_dim = 128
        features = torch.zeros(num_nodes, feature_dim)
        
        # Calcular mÃ©tricas bÃ¡sicas del grafo
        degree_dict = dict(G.degree())
        
        for node, node_id in self.node_to_id.items():
            if node in G.nodes():
                degree = degree_dict.get(node, 0)
                
                # Feature 0-9: One-hot grado (hasta 10)
                degree_cat = min(degree, 9)
                features[node_id, degree_cat] = 1.0
                
                # Feature 10: Grado normalizado
                max_degree = max(degree_dict.values()) if degree_dict else 1
                features[node_id, 10] = degree / max_degree
                
                # Feature 11: Indicador de actividad
                features[node_id, 11] = 1.0 if degree > 0 else 0.0
                
                # Features 12-127: Embedding aleatorio
                features[node_id, 12:] = torch.randn(feature_dim - 12) * 0.1
        
        return features
    
    def create_link_prediction_dataset(self, test_ratio: float = 0.2) -> Dict:
        """Crea dataset para predicciÃ³n de enlaces"""
        print("ğŸ”— Creando dataset de predicciÃ³n de enlaces para EvolveGCN...")
        
        all_positive_pairs = []
        all_negative_pairs = []
        all_timestamps = []
        
        for graph_data in self.temporal_graphs:
            edge_index = graph_data['edge_index']
            timestamp = graph_data['timestamp']
            num_nodes = graph_data['num_nodes']
            
            if edge_index.size(1) == 0:
                continue
            
            # Enlaces positivos
            positive_pairs = edge_index.t().unique(dim=0)
            positive_pairs = positive_pairs[positive_pairs[:, 0] < positive_pairs[:, 1]]
            
            # Enlaces negativos
            num_positive = positive_pairs.size(0)
            negative_pairs = self._sample_negative_pairs(positive_pairs, num_nodes, num_positive)
            
            # Agregar a listas
            all_positive_pairs.append(positive_pairs)
            all_negative_pairs.append(negative_pairs)
            
            # Timestamps
            pos_timestamps = torch.full((num_positive,), timestamp)
            neg_timestamps = torch.full((num_positive,), timestamp)
            all_timestamps.extend([pos_timestamps, neg_timestamps])
        
        # Combinar datos
        X_pairs = torch.cat(all_positive_pairs + all_negative_pairs, dim=0)
        y_labels = torch.cat([
            torch.ones(sum(pairs.size(0) for pairs in all_positive_pairs)),
            torch.zeros(sum(pairs.size(0) for pairs in all_negative_pairs))
        ])
        
        pair_timestamps = torch.cat(all_timestamps)
        
        # Train/test split
        indices = torch.randperm(X_pairs.size(0))
        split_idx = int(len(indices) * (1 - test_ratio))
        
        train_indices = indices[:split_idx]
        test_indices = indices[split_idx:]
        
        dataset = {
            'X_train_pairs': X_pairs[train_indices],
            'X_test_pairs': X_pairs[test_indices],
            'y_train': y_labels[train_indices],
            'y_test': y_labels[test_indices],
            'train_timestamps': pair_timestamps[train_indices],
            'test_timestamps': pair_timestamps[test_indices],
            'temporal_graphs': self.temporal_graphs,
            'node_mapping': {'node_to_id': self.node_to_id, 'id_to_node': self.id_to_node}
        }
        
        print(f"âœ… Dataset EvolveGCN creado:")
        print(f"   ğŸ“Š Train: {len(train_indices)} pares")
        print(f"   ğŸ“Š Test: {len(test_indices)} pares")
        
        return dataset
    
    def _sample_negative_pairs(self, positive_pairs: torch.Tensor, 
                              num_nodes: int, num_samples: int) -> torch.Tensor:
        """Muestrea pares negativos"""
        positive_set = set()
        for pair in positive_pairs:
            u, v = pair.tolist()
            positive_set.add((min(u, v), max(u, v)))
        
        negative_pairs = []
        attempts = 0
        max_attempts = num_samples * 10
        
        while len(negative_pairs) < num_samples and attempts < max_attempts:
            u = np.random.randint(0, num_nodes)
            v = np.random.randint(0, num_nodes)
            
            if u != v:
                pair = (min(u, v), max(u, v))
                if pair not in positive_set:
                    negative_pairs.append([u, v])
            
            attempts += 1
        
        # Rellenar si es necesario
        while len(negative_pairs) < num_samples:
            u = np.random.randint(0, num_nodes)
            v = np.random.randint(0, num_nodes)
            if u != v:
                negative_pairs.append([u, v])
        
        return torch.tensor(negative_pairs[:num_samples])


class EvolveGCNTrainer:
    """
    ğŸ‹ï¸ Entrenador de EvolveGCN-H
    ============================
    """
    
    def __init__(self, model: EvolveGCNH, device: torch.device):
        self.model = model.to(device)
        self.device = device
        self.train_losses = []
        self.val_metrics = []
        
    def train_model(self, dataset: Dict, epochs: int = 150, 
                   batch_size: int = 32, learning_rate: float = 0.01) -> Dict:
        """Entrena el modelo EvolveGCN-H"""
        print("ğŸ‹ï¸ Iniciando entrenamiento de EvolveGCN-H...")
        print(f"   ğŸ“Š Ã‰pocas: {epochs}")
        print(f"   ğŸ“¦ Batch size: {batch_size}")
        print(f"   ğŸ“ˆ Learning rate: {learning_rate}")
        
        # Preparar datos
        X_train = dataset['X_train_pairs']
        y_train = dataset['y_train']
        temporal_graphs = dataset['temporal_graphs']
        
        # Mover grafos temporales al dispositivo
        for i, graph_data in enumerate(temporal_graphs):
            for key, value in graph_data.items():
                if isinstance(value, torch.Tensor):
                    temporal_graphs[i][key] = value.to(self.device)
        
        # Split train/validation
        val_size = int(len(X_train) * 0.2)
        train_size = len(X_train) - val_size
        
        train_indices = torch.randperm(len(X_train))[:train_size]
        val_indices = torch.randperm(len(X_train))[train_size:train_size + val_size]
        
        # Crear DataLoaders
        train_dataset = TensorDataset(X_train[train_indices], y_train[train_indices])
        val_dataset = TensorDataset(X_train[val_indices], y_train[val_indices])
        
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
        
        # Configurar optimizador
        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=1e-4)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)
        criterion = nn.BCELoss()
        
        # Variables para early stopping
        best_val_loss = float('inf')
        patience_counter = 0
        patience = 15
        
        start_time = time.time()
        
        # Training loop
        for epoch in range(epochs):
            # Reset modelo para nueva Ã©poca
            self.model.reset_parameters()
            
            # Training phase
            self.model.train()
            train_loss = 0.0
            num_batches = 0
            
            for batch_pairs, batch_labels in train_loader:
                batch_pairs = batch_pairs.to(self.device)
                batch_labels = batch_labels.to(self.device).float()
                
                optimizer.zero_grad()
                
                # Forward pass
                predictions = self.model(
                    temporal_graphs=temporal_graphs,
                    target_pairs=batch_pairs,
                    time_step=epoch
                ).squeeze()
                
                # Loss
                loss = criterion(predictions, batch_labels)
                
                # Backward pass
                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                optimizer.step()
                
                train_loss += loss.item()
                num_batches += 1
            
            avg_train_loss = train_loss / num_batches
            self.train_losses.append(avg_train_loss)
            
            # Validation phase
            val_metrics = self._validate(val_loader, temporal_graphs, criterion, epoch)
            self.val_metrics.append(val_metrics)
            
            # Learning rate scheduling
            scheduler.step(val_metrics['loss'])
            
            # Early stopping
            if val_metrics['loss'] < best_val_loss:
                best_val_loss = val_metrics['loss']
                patience_counter = 0
                torch.save(self.model.state_dict(), 'best_evolvegcn_model.pth')
            else:
                patience_counter += 1
            
            # Print progress
            if (epoch + 1) % 20 == 0 or epoch == 0:
                elapsed = time.time() - start_time
                print(f"Ã‰poca {epoch+1:3d}/{epochs} | "
                      f"Train Loss: {avg_train_loss:.4f} | "
                      f"Val Loss: {val_metrics['loss']:.4f} | "
                      f"Val AUC: {val_metrics['auc']:.4f} | "
                      f"Time: {elapsed:.1f}s")
            
            # Early stopping
            if patience_counter >= patience:
                print(f"ğŸ›‘ Early stopping en Ã©poca {epoch+1}")
                break
        
        # Cargar mejor modelo
        self.model.load_state_dict(torch.load('best_evolvegcn_model.pth'))
        
        return {
            'train_losses': self.train_losses,
            'val_metrics': self.val_metrics,
            'total_epochs': epoch + 1,
            'best_val_loss': best_val_loss
        }
    
    def _validate(self, val_loader: DataLoader, temporal_graphs: List[Dict],
                 criterion: nn.Module, epoch: int) -> Dict:
        """ValidaciÃ³n del modelo"""
        self.model.eval()
        
        val_loss = 0.0
        all_predictions = []
        all_labels = []
        num_batches = 0
        
        with torch.no_grad():
            for batch_pairs, batch_labels in val_loader:
                batch_pairs = batch_pairs.to(self.device)
                batch_labels = batch_labels.to(self.device).float()
                
                # Forward pass
                predictions = self.model(
                    temporal_graphs=temporal_graphs,
                    target_pairs=batch_pairs,
                    time_step=epoch
                ).squeeze()
                
                # Loss
                loss = criterion(predictions, batch_labels)
                val_loss += loss.item()
                
                # Collect predictions
                all_predictions.extend(predictions.cpu().numpy())
                all_labels.extend(batch_labels.cpu().numpy())
                num_batches += 1
        
        # Calcular mÃ©tricas
        all_predictions = np.array(all_predictions)
        all_labels = np.array(all_labels)
        
        auc = roc_auc_score(all_labels, all_predictions)
        ap = average_precision_score(all_labels, all_predictions)
        
        pred_binary = (all_predictions > 0.5).astype(int)
        f1 = f1_score(all_labels, pred_binary)
        
        return {
            'loss': val_loss / num_batches,
            'auc': auc,
            'ap': ap,
            'f1': f1
        }
    
    def evaluate_test(self, dataset: Dict) -> Dict:
        """EvaluaciÃ³n en conjunto de test"""
        print("ğŸ“Š Evaluando EvolveGCN-H en conjunto de test...")
        
        self.model.eval()
        
        X_test = dataset['X_test_pairs'].to(self.device)
        y_test = dataset['y_test'].cpu().numpy()
        temporal_graphs = dataset['temporal_graphs']
        
        all_predictions = []
        batch_size = 64
        
        with torch.no_grad():
            for i in range(0, len(X_test), batch_size):
                batch_pairs = X_test[i:i+batch_size]
                
                if len(batch_pairs) == 0:
                    continue
                
                # Forward pass (usar Ãºltimo time_step)
                predictions = self.model(
                    temporal_graphs=temporal_graphs,
                    target_pairs=batch_pairs,
                    time_step=len(temporal_graphs)-1
                ).squeeze()
                
                all_predictions.extend(predictions.cpu().numpy())
        
        # Calcular mÃ©tricas
        all_predictions = np.array(all_predictions)
        
        auc_roc = roc_auc_score(y_test, all_predictions)
        auc_pr = average_precision_score(y_test, all_predictions)
        
        # F1 con diferentes thresholds
        thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]
        f1_scores = []
        
        for threshold in thresholds:
            pred_binary = (all_predictions > threshold).astype(int)
            f1 = f1_score(y_test, pred_binary)
            f1_scores.append(f1)
        
        best_threshold_idx = np.argmax(f1_scores)
        best_threshold = thresholds[best_threshold_idx]
        best_f1 = f1_scores[best_threshold_idx]
        
        results = {
            'auc_roc': auc_roc,
            'auc_pr': auc_pr,
            'best_f1': best_f1,
            'best_threshold': best_threshold,
            'f1_by_threshold': dict(zip(thresholds, f1_scores)),
            'predictions': all_predictions,
            'true_labels': y_test
        }
        
        print(f"ğŸ“Š RESULTADOS FINALES EVOLVEGCN-H:")
        print(f"   ğŸ¯ AUC-ROC: {auc_roc:.4f}")
        print(f"   ğŸ“ˆ AUC-PR: {auc_pr:.4f}")
        print(f"   âš–ï¸  Best F1: {best_f1:.4f} (threshold: {best_threshold})")
        
        return results


def main():
    """ğŸš€ FunciÃ³n principal - ImplementaciÃ³n EvolveGCN-H"""
    
    print("ğŸ§¬ EVOLVEGCN-H - IMPLEMENTACIÃ“N COMPLETA")
    print("=" * 60)
    print("Evolving Graph Convolutional Networks - Historical")
    print("Para predicciÃ³n de enlaces en redes semÃ¡nticas temporales")
    print()
    
    # ConfiguraciÃ³n
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”§ Dispositivo: {device}")
    
    # 1. Cargar y procesar datos
    print("\nğŸ“‚ FASE 1: CARGA DE DATOS")
    print("-" * 30)
    
    processor = TemporalGraphProcessor()
    
    try:
        network_info = processor.load_and_process()
        dataset = processor.create_link_prediction_dataset(test_ratio=0.2)
        print(f"âœ… Datos temporales cargados y procesados")
        
    except Exception as e:
        print(f"âŒ Error cargando datos: {e}")
        return
    
    # 2. Crear modelo
    print("\nğŸ§  FASE 2: CREACIÃ“N DEL MODELO")
    print("-" * 35)
    
    # Obtener dimensiones de features del primer grafo
    first_graph = dataset['temporal_graphs'][0]
    input_dim = first_graph['node_features'].size(1)
    
    model = EvolveGCNH(
        input_dim=input_dim,
        hidden_dim=64,
        output_dim=32,
        num_layers=2,
        dropout=0.1
    )
    
    num_params = sum(p.numel() for p in model.parameters())
    print(f"âœ… Modelo EvolveGCN-H creado")
    print(f"   ğŸ“Š ParÃ¡metros: {num_params:,}")
    print(f"   ğŸ—ï¸  Arquitectura: {input_dim}â†’64â†’32")
    
    # 3. Entrenar modelo
    print("\nğŸ‹ï¸ FASE 3: ENTRENAMIENTO")
    print("-" * 30)
    
    trainer = EvolveGCNTrainer(model, device)
    
    training_history = trainer.train_model(
        dataset=dataset,
        epochs=100,
        batch_size=32,
        learning_rate=0.01
    )
    
    # 4. EvaluaciÃ³n
    print("\nğŸ“Š FASE 4: EVALUACIÃ“N")
    print("-" * 25)
    
    evaluation_results = trainer.evaluate_test(dataset)
    
    # 5. Guardar resultados
    print("\nğŸ’¾ FASE 5: GUARDADO DE RESULTADOS")
    print("-" * 40)
    
    results_summary = {
        'model_name': 'EvolveGCN-H',
        'model_config': {
            'input_dim': input_dim,
            'hidden_dim': 64,
            'output_dim': 32,
            'num_layers': 2,
            'num_parameters': num_params
        },
        'evaluation_results': evaluation_results,
        'dataset_info': network_info,
        'timestamp': datetime.now().isoformat()
    }
    
    # Guardar modelo
    torch.save({
        'model_state_dict': model.state_dict(),
        'model_config': results_summary['model_config'],
        'results': evaluation_results
    }, 'evolvegcn_model_complete.pth')
    
    print(f"âœ… Resultados guardados:")
    print(f"   ğŸ§  evolvegcn_model_complete.pth")
    
    # 6. Resumen final
    print(f"\nğŸ‰ IMPLEMENTACIÃ“N EVOLVEGCN-H COMPLETADA")
    print("=" * 50)
    print(f"ğŸ“Š RESULTADOS FINALES:")
    print(f"   ğŸ¯ AUC-ROC: {evaluation_results['auc_roc']:.4f}")
    print(f"   ğŸ“ˆ AUC-PR: {evaluation_results['auc_pr']:.4f}")
    print(f"   âš–ï¸  F1-Score: {evaluation_results['best_f1']:.4f}")
    
    return results_summary


if __name__ == "__main__":
    results = main()
