#!/usr/bin/env python3
"""
üß¨ IMPLEMENTACI√ìN EVOLVEGCN-H - EVOLVING GRAPH CONVOLUTIONAL NETWORKS
=====================================================================

Implementaci√≥n completa de EvolveGCN-H para predicci√≥n de enlaces en redes 
sem√°nticas temporales usando los datos de metadatos acad√©micos.

Caracter√≠sticas:
- EvolveGCN-H (Historical) con GRU para evoluci√≥n temporal
- Evoluci√≥n de par√°metros de GCN a trav√©s del tiempo
- Optimizado para secuencias temporales largas (25 a√±os)
- Comparaci√≥n directa vs baseline y TDGNN

Basado en:
"EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs"
Pareja et al., AAAI 2020

Autor: Sistema de Implementaci√≥n EvolveGCN
Fecha: Julio 2025
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'External_repos', 'EvolveGCN'))

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import pandas as pd
import networkx as nx
from sklearn.metrics import roc_auc_score, average_precision_score, f1_score
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json
import pickle
from typing import Dict, List, Tuple, Optional
from collections import defaultdict
import time
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Importar m√≥dulos de EvolveGCN
try:
    from egcn_h import EGCN_H
    from utils import build_random_hyper_params
except ImportError:
    print("‚ö†Ô∏è No se pudo importar EvolveGCN. Usando implementaci√≥n propia.")


class EvolveGCNH(nn.Module):
    """
    üß¨ EvolveGCN-H - Historical Evolution
    ====================================
    
    Versi√≥n simplificada de EvolveGCN-H que evoluciona los par√°metros de GCN
    usando GRU basado en la historia temporal.
    """
    
    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int, 
                 num_layers: int = 2, dropout: float = 0.1):
        super(EvolveGCNH, self).__init__()
        
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        self.num_layers = num_layers
        self.dropout = dropout
        
        # GRU para evoluci√≥n temporal de par√°metros
        self.weight_evolve_gru = nn.GRU(
            input_size=hidden_dim * hidden_dim,  # Tama√±o de matriz de pesos GCN
            hidden_size=hidden_dim * hidden_dim,
            num_layers=1,
            batch_first=True
        )
        
        # Par√°metros iniciales de GCN
        self.initial_weights = nn.Parameter(
            torch.randn(hidden_dim, hidden_dim) * 0.1
        )
        
        # Capas fijas
        self.input_projection = nn.Linear(input_dim, hidden_dim)
        self.output_projection = nn.Linear(hidden_dim, output_dim)
        
        # Link predictor
        self.link_predictor = nn.Sequential(
            nn.Linear(output_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim // 2, 1)
        )
        
        # Estado oculto del GRU
        self.gru_hidden = None
        
    def reset_parameters(self):
        """Reinicia par√°metros del modelo"""
        if self.gru_hidden is not None:
            self.gru_hidden = self.gru_hidden.detach()
            self.gru_hidden.zero_()
        
    def evolve_weights(self, time_step: int) -> torch.Tensor:
        """
        Evoluciona los pesos de GCN usando GRU
        
        Args:
            time_step: Paso temporal actual
        
        Returns:
            Nuevos pesos de GCN evolucionados
        """
        batch_size = 1
        device = self.initial_weights.device
        
        # Preparar input para GRU (pesos actuales aplanados)
        current_weights = self.initial_weights.view(1, 1, -1).detach()
        
        # Inicializar estado oculto si es necesario
        if self.gru_hidden is None:
            self.gru_hidden = torch.zeros(
                1, batch_size, self.hidden_dim * self.hidden_dim,
                device=device, requires_grad=False
            )
        else:
            # Detach para evitar problemas de gradiente
            self.gru_hidden = self.gru_hidden.detach()
        
        # Evolucionar pesos con GRU
        output, self.gru_hidden = self.weight_evolve_gru(
            current_weights, self.gru_hidden
        )
        
        # Reshape a matriz de pesos
        evolved_weights = output.view(self.hidden_dim, self.hidden_dim)
        
        return evolved_weights
        
    def gcn_layer(self, x: torch.Tensor, edge_index: torch.Tensor, 
                  weights: torch.Tensor) -> torch.Tensor:
        """
        Capa GCN con pesos evolucionados
        
        Args:
            x: Features de nodos [num_nodes, hidden_dim]
            edge_index: √çndices de aristas [2, num_edges]
            weights: Pesos GCN evolucionados [hidden_dim, hidden_dim]
        
        Returns:
            Features actualizadas [num_nodes, hidden_dim]
        """
        num_nodes = x.size(0)
        
        # Crear matriz de adyacencia
        adj = torch.zeros(num_nodes, num_nodes, device=x.device)
        if edge_index.size(1) > 0:
            adj[edge_index[0], edge_index[1]] = 1.0
            
        # Normalizaci√≥n sim√©trica
        degree = adj.sum(dim=1)
        degree[degree == 0] = 1  # Evitar divisi√≥n por cero
        d_inv_sqrt = torch.diag(degree.pow(-0.5))
        adj_norm = d_inv_sqrt @ adj @ d_inv_sqrt
        
        # Aplicar convoluci√≥n con pesos evolucionados
        x_transformed = x @ weights
        output = adj_norm @ x_transformed
        
        return output
    
    def forward(self, temporal_graphs: List[Dict], target_pairs: torch.Tensor,
                time_step: int = 0) -> torch.Tensor:
        """
        Forward pass de EvolveGCN-H
        
        Args:
            temporal_graphs: Lista de grafos temporales
            target_pairs: Pares de nodos a predecir [batch_size, 2]
            time_step: Paso temporal actual
        
        Returns:
            Probabilidades de enlaces [batch_size, 1]
        """
        if not temporal_graphs:
            # Crear output dummy si no hay grafos
            batch_size = target_pairs.size(0)
            return torch.zeros(batch_size, 1, device=target_pairs.device)
        
        # Usar el primer grafo temporal (simplificado)
        graph_data = temporal_graphs[0]
        edge_index = graph_data['edge_index']
        node_features = graph_data.get('node_features')
        
        if node_features is None:
            # Crear features dummy
            num_nodes = max(edge_index.max().item() + 1, target_pairs.max().item() + 1)
            node_features = torch.randn(num_nodes, self.input_dim, device=edge_index.device)
        
        # Proyecci√≥n inicial
        x = self.input_projection(node_features)
        
        # Evolucionar pesos GCN
        evolved_weights = self.evolve_weights(time_step)
        
        # Aplicar capas GCN evolucionadas
        for layer in range(self.num_layers):
            x = self.gcn_layer(x, edge_index, evolved_weights)
            x = F.relu(x)
            x = F.dropout(x, self.dropout, training=self.training)
        
        # Proyecci√≥n final
        node_embeddings = self.output_projection(x)
        
        # Predicci√≥n de enlaces
        source_embeddings = node_embeddings[target_pairs[:, 0]]
        target_embeddings = node_embeddings[target_pairs[:, 1]]
        
        # Combinar embeddings
        pair_embeddings = torch.cat([source_embeddings, target_embeddings], dim=1)
        
        # Predecir probabilidad de enlace
        link_scores = self.link_predictor(pair_embeddings)
        link_probs = torch.sigmoid(link_scores)
        
        return link_probs


class TemporalGraphProcessor:
    """
    üìä Procesador de Grafos Temporales para EvolveGCN
    ================================================
    
    Convierte datos de NetworkX a formato compatible con EvolveGCN
    """
    
    def __init__(self, temporal_networks_path: str = "../temporal_networks/networks"):
        self.temporal_networks_path = Path(temporal_networks_path)
        self.node_to_id = {}
        self.id_to_node = {}
        self.temporal_graphs = []
        
    def load_and_process(self) -> Dict:
        """Carga y procesa todas las redes temporales"""
        print("üìÇ Cargando redes temporales para EvolveGCN...")
        
        network_files = list(self.temporal_networks_path.glob("semantic_network_*.graphml"))
        network_files.sort()
        
        print(f"Encontrados {len(network_files)} archivos de red")
        
        all_nodes = set()
        temporal_data = []
        
        # Cargar todos los grafos
        for i, file_path in enumerate(network_files):
            period = file_path.stem.replace('semantic_network_', '')
            print(f"  üìà Cargando {period}...")
            
            try:
                G = nx.read_graphml(file_path)
                temporal_data.append({
                    'period': period,
                    'graph': G,
                    'timestamp': self._period_to_timestamp(period)
                })
                all_nodes.update(G.nodes())
                
            except Exception as e:
                print(f"  ‚ùå Error cargando {file_path}: {e}")
                continue
        
        # Crear mapeo de nodos
        self.node_to_id = {node: i for i, node in enumerate(sorted(all_nodes))}
        self.id_to_node = {i: node for node, i in self.node_to_id.items()}
        
        print(f"üìä Total de nodos √∫nicos: {len(all_nodes)}")
        
        # Convertir a formato tensor
        for data in temporal_data:
            graph_tensor = self._convert_to_tensor(data['graph'], data['timestamp'])
            self.temporal_graphs.append(graph_tensor)
        
        return {
            'num_nodes': len(all_nodes),
            'num_periods': len(temporal_data),
            'node_mapping': {'node_to_id': self.node_to_id, 'id_to_node': self.id_to_node},
            'temporal_graphs': self.temporal_graphs
        }
    
    def _period_to_timestamp(self, period: str) -> float:
        """Convierte per√≠odo a timestamp"""
        try:
            year_part = period.split('-')[0]
            start_year = int(year_part)
            return float(start_year - 2000)
        except:
            return 0.0
    
    def _convert_to_tensor(self, G: nx.Graph, timestamp: float) -> Dict:
        """Convierte grafo NetworkX a tensores PyTorch"""
        
        # Convertir aristas
        edges = []
        edge_weights = []
        
        for u, v, data in G.edges(data=True):
            if u in self.node_to_id and v in self.node_to_id:
                u_id = self.node_to_id[u]
                v_id = self.node_to_id[v]
                
                edges.append([u_id, v_id])
                edges.append([v_id, u_id])  # Grafo no dirigido
                
                weight = data.get('weight', 1.0)
                edge_weights.extend([weight, weight])
        
        # Crear features de nodos b√°sicas
        num_nodes = len(self.node_to_id)
        node_features = self._create_node_features(G, num_nodes)
        
        graph_data = {
            'timestamp': timestamp,
            'edge_index': torch.tensor(edges).t().contiguous() if edges else torch.empty((2, 0), dtype=torch.long),
            'edge_weights': torch.tensor(edge_weights, dtype=torch.float) if edge_weights else torch.empty(0),
            'node_features': node_features,
            'num_nodes': num_nodes,
            'num_edges': len(edges)
        }
        
        return graph_data
    
    def _create_node_features(self, G: nx.Graph, num_nodes: int) -> torch.Tensor:
        """Crea features b√°sicas para los nodos"""
        feature_dim = 128
        features = torch.zeros(num_nodes, feature_dim)
        
        # Calcular m√©tricas b√°sicas del grafo
        degree_dict = dict(G.degree())
        
        for node, node_id in self.node_to_id.items():
            if node in G.nodes():
                degree = degree_dict.get(node, 0)
                
                # Feature 0-9: One-hot grado (hasta 10)
                degree_cat = min(degree, 9)
                features[node_id, degree_cat] = 1.0
                
                # Feature 10: Grado normalizado
                max_degree = max(degree_dict.values()) if degree_dict else 1
                features[node_id, 10] = degree / max_degree
                
                # Feature 11: Indicador de actividad
                features[node_id, 11] = 1.0 if degree > 0 else 0.0
                
                # Features 12-127: Embedding aleatorio
                features[node_id, 12:] = torch.randn(feature_dim - 12) * 0.1
        
        return features
    
    def create_link_prediction_dataset(self, test_ratio: float = 0.2) -> Dict:
        """Crea dataset para predicci√≥n de enlaces"""
        print("üîó Creando dataset de predicci√≥n de enlaces para EvolveGCN...")
        
        all_positive_pairs = []
        all_negative_pairs = []
        all_timestamps = []
        
        for graph_data in self.temporal_graphs:
            edge_index = graph_data['edge_index']
            timestamp = graph_data['timestamp']
            num_nodes = graph_data['num_nodes']
            
            if edge_index.size(1) == 0:
                continue
            
            # Enlaces positivos
            positive_pairs = edge_index.t().unique(dim=0)
            positive_pairs = positive_pairs[positive_pairs[:, 0] < positive_pairs[:, 1]]
            
            # Enlaces negativos
            num_positive = positive_pairs.size(0)
            negative_pairs = self._sample_negative_pairs(positive_pairs, num_nodes, num_positive)
            
            # Agregar a listas
            all_positive_pairs.append(positive_pairs)
            all_negative_pairs.append(negative_pairs)
            
            # Timestamps
            pos_timestamps = torch.full((num_positive,), timestamp)
            neg_timestamps = torch.full((num_positive,), timestamp)
            all_timestamps.extend([pos_timestamps, neg_timestamps])
        
        # Combinar datos
        X_pairs = torch.cat(all_positive_pairs + all_negative_pairs, dim=0)
        y_labels = torch.cat([
            torch.ones(sum(pairs.size(0) for pairs in all_positive_pairs)),
            torch.zeros(sum(pairs.size(0) for pairs in all_negative_pairs))
        ])
        
        pair_timestamps = torch.cat(all_timestamps)
        
        # Train/test split
        indices = torch.randperm(X_pairs.size(0))
        split_idx = int(len(indices) * (1 - test_ratio))
        
        train_indices = indices[:split_idx]
        test_indices = indices[split_idx:]
        
        dataset = {
            'X_train_pairs': X_pairs[train_indices],
            'X_test_pairs': X_pairs[test_indices],
            'y_train': y_labels[train_indices],
            'y_test': y_labels[test_indices],
            'train_timestamps': pair_timestamps[train_indices],
            'test_timestamps': pair_timestamps[test_indices],
            'temporal_graphs': self.temporal_graphs,
            'node_mapping': {'node_to_id': self.node_to_id, 'id_to_node': self.id_to_node}
        }
        
        print(f"‚úÖ Dataset EvolveGCN creado:")
        print(f"   üìä Train: {len(train_indices)} pares")
        print(f"   üìä Test: {len(test_indices)} pares")
        
        return dataset
    
    def _sample_negative_pairs(self, positive_pairs: torch.Tensor, 
                              num_nodes: int, num_samples: int) -> torch.Tensor:
        """Muestrea pares negativos"""
        positive_set = set()
        for pair in positive_pairs:
            u, v = pair.tolist()
            positive_set.add((min(u, v), max(u, v)))
        
        negative_pairs = []
        attempts = 0
        max_attempts = num_samples * 10
        
        while len(negative_pairs) < num_samples and attempts < max_attempts:
            u = np.random.randint(0, num_nodes)
            v = np.random.randint(0, num_nodes)
            
            if u != v:
                pair = (min(u, v), max(u, v))
                if pair not in positive_set:
                    negative_pairs.append([u, v])
            
            attempts += 1
        
        # Rellenar si es necesario
        while len(negative_pairs) < num_samples:
            u = np.random.randint(0, num_nodes)
            v = np.random.randint(0, num_nodes)
            if u != v:
                negative_pairs.append([u, v])
        
        return torch.tensor(negative_pairs[:num_samples])


class EvolveGCNTrainer:
    """
    üèãÔ∏è Entrenador de EvolveGCN-H
    ============================
    """
    
    def __init__(self, model: EvolveGCNH, device: torch.device):
        self.model = model.to(device)
        self.device = device
        self.train_losses = []
        self.val_metrics = []
        
    def train_model(self, dataset: Dict, epochs: int = 150, 
                   batch_size: int = 32, learning_rate: float = 0.01) -> Dict:
        """Entrena el modelo EvolveGCN-H"""
        print("üèãÔ∏è Iniciando entrenamiento de EvolveGCN-H...")
        print(f"   üìä √âpocas: {epochs}")
        print(f"   üì¶ Batch size: {batch_size}")
        print(f"   üìà Learning rate: {learning_rate}")
        
        # Preparar datos
        X_train = dataset['X_train_pairs']
        y_train = dataset['y_train']
        temporal_graphs = dataset['temporal_graphs']
        
        # Mover grafos temporales al dispositivo
        for i, graph_data in enumerate(temporal_graphs):
            for key, value in graph_data.items():
                if isinstance(value, torch.Tensor):
                    temporal_graphs[i][key] = value.to(self.device)
        
        # Split train/validation
        val_size = int(len(X_train) * 0.2)
        train_size = len(X_train) - val_size
        
        train_indices = torch.randperm(len(X_train))[:train_size]
        val_indices = torch.randperm(len(X_train))[train_size:train_size + val_size]
        
        # Crear DataLoaders
        train_dataset = TensorDataset(X_train[train_indices], y_train[train_indices])
        val_dataset = TensorDataset(X_train[val_indices], y_train[val_indices])
        
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
        
        # Configurar optimizador
        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=1e-4)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)
        criterion = nn.BCELoss()
        
        # Variables para early stopping
        best_val_loss = float('inf')
        patience_counter = 0
        patience = 15
        
        start_time = time.time()
        
        # Training loop
        for epoch in range(epochs):
            # Reset modelo para nueva √©poca
            self.model.reset_parameters()
            
            # Training phase
            self.model.train()
            train_loss = 0.0
            num_batches = 0
            
            for batch_pairs, batch_labels in train_loader:
                batch_pairs = batch_pairs.to(self.device)
                batch_labels = batch_labels.to(self.device).float()
                
                optimizer.zero_grad()
                
                # Forward pass
                predictions = self.model(
                    temporal_graphs=temporal_graphs,
                    target_pairs=batch_pairs,
                    time_step=epoch
                ).squeeze()
                
                # Loss
                loss = criterion(predictions, batch_labels)
                
                # Backward pass
                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                optimizer.step()
                
                train_loss += loss.item()
                num_batches += 1
            
            avg_train_loss = train_loss / num_batches
            self.train_losses.append(avg_train_loss)
            
            # Validation phase
            val_metrics = self._validate(val_loader, temporal_graphs, criterion, epoch)
            self.val_metrics.append(val_metrics)
            
            # Learning rate scheduling
            scheduler.step(val_metrics['loss'])
            
            # Early stopping
            if val_metrics['loss'] < best_val_loss:
                best_val_loss = val_metrics['loss']
                patience_counter = 0
                torch.save(self.model.state_dict(), 'best_evolvegcn_model.pth')
            else:
                patience_counter += 1
            
            # Print progress
            if (epoch + 1) % 20 == 0 or epoch == 0:
                elapsed = time.time() - start_time
                print(f"√âpoca {epoch+1:3d}/{epochs} | "
                      f"Train Loss: {avg_train_loss:.4f} | "
                      f"Val Loss: {val_metrics['loss']:.4f} | "
                      f"Val AUC: {val_metrics['auc']:.4f} | "
                      f"Time: {elapsed:.1f}s")
            
            # Early stopping
            if patience_counter >= patience:
                print(f"üõë Early stopping en √©poca {epoch+1}")
                break
        
        # Cargar mejor modelo
        self.model.load_state_dict(torch.load('best_evolvegcn_model.pth'))
        
        return {
            'train_losses': self.train_losses,
            'val_metrics': self.val_metrics,
            'total_epochs': epoch + 1,
            'best_val_loss': best_val_loss
        }
    
    def _validate(self, val_loader: DataLoader, temporal_graphs: List[Dict],
                 criterion: nn.Module, epoch: int) -> Dict:
        """Validaci√≥n del modelo"""
        self.model.eval()
        
        val_loss = 0.0
        all_predictions = []
        all_labels = []
        num_batches = 0
        
        with torch.no_grad():
            for batch_pairs, batch_labels in val_loader:
                batch_pairs = batch_pairs.to(self.device)
                batch_labels = batch_labels.to(self.device).float()
                
                # Forward pass
                predictions = self.model(
                    temporal_graphs=temporal_graphs,
                    target_pairs=batch_pairs,
                    time_step=epoch
                ).squeeze()
                
                # Loss
                loss = criterion(predictions, batch_labels)
                val_loss += loss.item()
                
                # Collect predictions
                all_predictions.extend(predictions.cpu().numpy())
                all_labels.extend(batch_labels.cpu().numpy())
                num_batches += 1
        
        # Calcular m√©tricas
        all_predictions = np.array(all_predictions)
        all_labels = np.array(all_labels)
        
        auc = roc_auc_score(all_labels, all_predictions)
        ap = average_precision_score(all_labels, all_predictions)
        
        pred_binary = (all_predictions > 0.5).astype(int)
        f1 = f1_score(all_labels, pred_binary)
        
        return {
            'loss': val_loss / num_batches,
            'auc': auc,
            'ap': ap,
            'f1': f1
        }
    
    def evaluate_test(self, dataset: Dict) -> Dict:
        """Evaluaci√≥n en conjunto de test"""
        print("üìä Evaluando EvolveGCN-H en conjunto de test...")
        
        self.model.eval()
        
        X_test = dataset['X_test_pairs'].to(self.device)
        y_test = dataset['y_test'].cpu().numpy()
        temporal_graphs = dataset['temporal_graphs']
        
        all_predictions = []
        batch_size = 64
        
        with torch.no_grad():
            for i in range(0, len(X_test), batch_size):
                batch_pairs = X_test[i:i+batch_size]
                
                if len(batch_pairs) == 0:
                    continue
                
                # Forward pass (usar √∫ltimo time_step)
                predictions = self.model(
                    temporal_graphs=temporal_graphs,
                    target_pairs=batch_pairs,
                    time_step=len(temporal_graphs)-1
                ).squeeze()
                
                all_predictions.extend(predictions.cpu().numpy())
        
        # Calcular m√©tricas
        all_predictions = np.array(all_predictions)
        
        auc_roc = roc_auc_score(y_test, all_predictions)
        auc_pr = average_precision_score(y_test, all_predictions)
        
        # F1 con diferentes thresholds
        thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]
        f1_scores = []
        
        for threshold in thresholds:
            pred_binary = (all_predictions > threshold).astype(int)
            f1 = f1_score(y_test, pred_binary)
            f1_scores.append(f1)
        
        best_threshold_idx = np.argmax(f1_scores)
        best_threshold = thresholds[best_threshold_idx]
        best_f1 = f1_scores[best_threshold_idx]
        
        results = {
            'auc_roc': auc_roc,
            'auc_pr': auc_pr,
            'best_f1': best_f1,
            'best_threshold': best_threshold,
            'f1_by_threshold': dict(zip(thresholds, f1_scores)),
            'predictions': all_predictions,
            'true_labels': y_test
        }
        
        print(f"üìä RESULTADOS FINALES EVOLVEGCN-H:")
        print(f"   üéØ AUC-ROC: {auc_roc:.4f}")
        print(f"   üìà AUC-PR: {auc_pr:.4f}")
        print(f"   ‚öñÔ∏è  Best F1: {best_f1:.4f} (threshold: {best_threshold})")
        
        return results


def main():
    """üöÄ Funci√≥n principal - Implementaci√≥n EvolveGCN-H"""
    
    print("üß¨ EVOLVEGCN-H - IMPLEMENTACI√ìN COMPLETA")
    print("=" * 60)
    print("Evolving Graph Convolutional Networks - Historical")
    print("Para predicci√≥n de enlaces en redes sem√°nticas temporales")
    print()
    
    # Configuraci√≥n
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"üîß Dispositivo: {device}")
    
    # 1. Cargar y procesar datos
    print("\nüìÇ FASE 1: CARGA DE DATOS")
    print("-" * 30)
    
    processor = TemporalGraphProcessor()
    
    try:
        network_info = processor.load_and_process()
        dataset = processor.create_link_prediction_dataset(test_ratio=0.2)
        print(f"‚úÖ Datos temporales cargados y procesados")
        
    except Exception as e:
        print(f"‚ùå Error cargando datos: {e}")
        return
    
    # 2. Crear modelo
    print("\nüß† FASE 2: CREACI√ìN DEL MODELO")
    print("-" * 35)
    
    # Obtener dimensiones de features del primer grafo
    first_graph = dataset['temporal_graphs'][0]
    input_dim = first_graph['node_features'].size(1)
    
    model = EvolveGCNH(
        input_dim=input_dim,
        hidden_dim=64,
        output_dim=32,
        num_layers=2,
        dropout=0.1
    )
    
    num_params = sum(p.numel() for p in model.parameters())
    print(f"‚úÖ Modelo EvolveGCN-H creado")
    print(f"   üìä Par√°metros: {num_params:,}")
    print(f"   üèóÔ∏è  Arquitectura: {input_dim}‚Üí64‚Üí32")
    
    # 3. Entrenar modelo
    print("\nüèãÔ∏è FASE 3: ENTRENAMIENTO")
    print("-" * 30)
    
    trainer = EvolveGCNTrainer(model, device)
    
    training_history = trainer.train_model(
        dataset=dataset,
        epochs=100,
        batch_size=32,
        learning_rate=0.01
    )
    
    # 4. Evaluaci√≥n
    print("\nüìä FASE 4: EVALUACI√ìN")
    print("-" * 25)
    
    evaluation_results = trainer.evaluate_test(dataset)
    
    # 5. Guardar resultados
    print("\nüíæ FASE 5: GUARDADO DE RESULTADOS")
    print("-" * 40)
    
    results_summary = {
        'model_name': 'EvolveGCN-H',
        'model_config': {
            'input_dim': input_dim,
            'hidden_dim': 64,
            'output_dim': 32,
            'num_layers': 2,
            'num_parameters': num_params
        },
        'evaluation_results': evaluation_results,
        'dataset_info': network_info,
        'timestamp': datetime.now().isoformat()
    }
    
    # Guardar modelo
    torch.save({
        'model_state_dict': model.state_dict(),
        'model_config': results_summary['model_config'],
        'results': evaluation_results
    }, 'evolvegcn_model_complete.pth')
    
    print(f"‚úÖ Resultados guardados:")
    print(f"   üß† evolvegcn_model_complete.pth")
    
    # 6. Resumen final
    print(f"\nüéâ IMPLEMENTACI√ìN EVOLVEGCN-H COMPLETADA")
    print("=" * 50)
    print(f"üìä RESULTADOS FINALES:")
    print(f"   üéØ AUC-ROC: {evaluation_results['auc_roc']:.4f}")
    print(f"   üìà AUC-PR: {evaluation_results['auc_pr']:.4f}")
    print(f"   ‚öñÔ∏è  F1-Score: {evaluation_results['best_f1']:.4f}")
    
    return results_summary


if __name__ == "__main__":
    results = main()
